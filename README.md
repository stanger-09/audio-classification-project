# ASiT: Localâ€“Global Audio Spectrogram Vision Transformer  
### **Automated Speaker Identification Using Audio Spectrogram Transformers**

ASiT is an advanced deep learning system designed for **speaker identification** using audio spectrograms.  
It implements:

- **Global Spectrogram Masking (GMML)**
- **Localâ€“Global Feature Fusion**
- **Self-Supervised Representation Learning**
- **Transformer-based Audio Encoder**

Traditionally, speaker identification teams spent **weeks** analyzing audio data manually.  
ASiT reduces this to **seconds**, offering fast, accurate, scalable predictions.

---

## ðŸ”¥ Key Features

- **Vision Transformer (ViT)-inspired audio encoder**
- **Localâ€“Global spectrogram masking strategy**
- **Fully modular codebase**
- **High accuracy speaker prediction**
- **Efficient PyTorch training & inference pipeline**
- **Self-contained preprocessing utilities**
- **Production-ready architecture**

---

## ðŸ“‚ Project Structure
"""
ASiT/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ inference/
â”‚ â”‚ â”œâ”€â”€ preprocess_audio.py
â”‚ â”‚ â”œâ”€â”€ predict.py
â”‚ â”‚ â””â”€â”€ pycache/
â”‚ â”‚
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ wav2vec_classifier.py
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â””â”€â”€ pycache/
â”‚ â”‚
â”‚ â”œâ”€â”€ training/
â”‚ â”‚ â”œâ”€â”€ train_epoch.py
â”‚ â”‚ â”œâ”€â”€ train_full.py
â”‚ â”‚ â”œâ”€â”€ collate_fn.py
â”‚ â”‚ â”œâ”€â”€ accuracy.py
â”‚ â”‚ â””â”€â”€ pycache/
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”œâ”€â”€ unzip_data.py
â”‚ â”‚ â””â”€â”€ init.py
â”‚ â”‚
â”‚ â”œâ”€â”€ main_train.py
â”‚ â””â”€â”€ inference_main.py
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
"""
